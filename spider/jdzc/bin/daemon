#!/bin/bash
#脚本路径
path=$(cd "$(dirname "$0")";pwd)
#虚拟环境路径
env_path=$(echo $path | awk -F"spider" '{print $1}')env/bin/activate
#日志路径
log_path=$(echo $path |awk -F"/bin" '{print $1}')/log
spider_log=$(echo $path |awk -F"/bin" '{print $1}')/log/spider.log
check_log=$(echo $path |awk -F"/bin" '{print $1}')/log/check.log
time_now=$(date '+%Y-%m-%d-%T')

cd $path
source $env_path
source /etc/profile
python=$(which python)
while [ 1 -eq 1 ]
do
	#先爬去url地址
	echo $time_now"------脚本$0 执行$path/url_spider脚本开始爬取url地址" >> $check_log
	nohup sh $path/url_spider  > $spider_log 2>&1 &
	sleep 2
	url_spider_pid=$(ps -ef |grep "scrapy crawl url_spider" |grep -v grep |awk '{print $2}'|wc -l)
	while [ "$url_spider_pid" -gt 0 ]
	do
		sleep 5
		url_spider_pid=$(ps -ef |grep "scrapy crawl url_spider" |grep -v grep |awk '{print $2}'|wc -l)
	done
	echo $time_now"------脚本$0 执行$path/url_spider脚本爬取url地址完成" >> $check_log
	#url地址爬去完成进行检测
	echo $time_now"------脚本$0 执行$path/check_url.py检测url数量" >> $check_log
	$phthon $path/check_url.py
	status_id=$?
	#如果内容表没有内容,则执行如下操作
	if [ $status_id -eq 1 ];then
		echo "检测结果为1" >> $check_log
		echo $time_now"------内容表url地址为空,脚本$0 执行$path/jdzc_spider脚本开始爬取内容" >> $check_log
		nohup sh $path/jdzc_spider >> $spider_log 2>&1 &
		sleep 2
		jdzc_spider_pid=$(ps -ef |grep "scrapy crawl jdzc_spider" |grep -v grep |awk '{print $2}'|wc -l)
		while [ "$jdzc_spider_pid" -gt 0 ]
		do
			sleep 2
			jdzc_spider_pid=$(ps -ef |grep "scrapy crawl jdzc_spider" |grep -v grep |awk '{print $2}'|wc -l)
		done
		echo $time_now"------脚本$0 执行$path/jdzc_spider脚本爬取内容完成" >> $check_log
		echo $time_now"------脚本$0 执行$path/remove_url.py脚本" >> $check_log
		$python $path/remove_url.py
		if [ $? -eq 0 ];then
			echo $time_now"------脚本$0 执行$path/remove_url.py脚本清除url地址完成" >> $check_log
		else
			echo $time_now"------脚本$0 执行$path/remove_url.py清除url地址失败,请手动查看" >> $check_log
		fi
		sleep 36000
			
	#如果内容表有内容,地址表没有地址,则执行如下操作
	elif [ $status_id -eq  2 ];then
		echo $time_now"------url地址没有更新,不执行任何操作等待10小时" >> $check_log 
		sleep 36000

	#如果内容表有内容,地址表地址有更新,则执行如下操作
	elif [ $status_id -eq 3 ];then
		echo $time_now"------内容表有内容,url地址有更新,$0 脚本执行$path/new_jdzc_spider脚本爬取新增内容" >> $check_log
		nohup sh $path/new_jdzc_spider >> $spider_log 2>&1 &
		sleep 2
		new_jdzc_spider_pid=$(ps -ef |grep "scrapy crawl new_jdzc_spider" |grep -v grep |awk '{print $2}'|wc -l)
		while [ "$new_jdzc_spider_pid" -gt 0 ]
		do
			sleep 2
			new_jdzc_spider_pid=$(ps -ef |grep "scrapy crawl new_jdzc_spider" |grep -v grep |awk '{print $2}'|wc -l)
		done
		echo $time_now"------脚本$0 执行脚本$path/new_jdzc_spider完成" >> $check_log
		echo $time_now"------脚本$0 执行$path/remove_url.py脚本" >> $check_log
		$python $path/remove_url.py
		if [ $? -eq 0 ];then
			echo $time_now"------脚本$0 执行$path/remove_url.py脚本清除url地址完成" >> $check_log
		else
			echo $time_now"------脚本$0 执行$path/remove_url.py清除url地址失败,请手动查看" >> $check_log
		fi
		sleep 36000
	else
		sleep 36000
	fi
done
