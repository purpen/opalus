#!/bin/bash
#脚本路径
path=$(cd "$(dirname "$0")";pwd)
#虚拟环境路径
env_path=$(echo $path | awk -F"spider" '{print $1}')env/bin/activate
#日志路径
log_path=$(echo $path |awk -F"/bin" '{print $1}')/log
spider_log=$(echo $path |awk -F"/bin" '{print $1}')/log/spider.log
check_log=$(echo $path |awk -F"/bin" '{print $1}')/log/check.log
time_now=$(date '+%Y-%m-%d-%T')

cd $log_path
source $env_path
source /etc/profile
python=$(which python)
echo $time_now"------脚本$0 执行scrapy crawl url_spider爬取url地址" >> $check_log
nohup scrapy crawl url_spider > $spider_log 2>&1 &
sleep 5
url_spider_pid=$(ps -ef |grep "scrapy crawl url_spider" |grep -v grep |awk '{print $2}'|wc -l)
while [ "$url_spider_pid" -gt 0 ]
do
	sleep 2
	url_spider_pid=$(ps -ef |grep "scrapy crawl url_spider" |grep -v grep |awk '{print $2}'|wc -l)
done
pid=$(ps aux |grep phantomjs |grep -v grep |awk '{print $2}'|wc -l)
if [ "$pid" -eq 0 ];then
	echo $time_now"------脚本$0 执行scrapy crawl url_spider地址爬取完成" >> $check_log
else
	ps aux |grep phantomjs |grep -v grep |awk '{print $2}'|xargs kill -9
	pid=$(ps aux |grep phantomjs |grep -v grep |awk '{print $2}'|wc -l)
	if [ "$pid" -eq 0 ];then
		echo $time_now"------脚本$0 执行scrapy crawl url_spider地址爬取完成" >> $check_log
	else
		echo $time_now"------脚本$0 有遗留进程请手动查看并操作" >> $check_log
	fi
fi
echo -e "\n\n" >> $check_log
